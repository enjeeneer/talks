{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976aea77",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conservative World Models\n",
    "\n",
    "### Scott Jeen, Tom Bewley & Jonathan Cullen\n",
    "\n",
    "### Refficiency Lunch Seminar, 10th October 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949f043a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some Motivating Statements\n",
    "\n",
    "1. We'd like to control many processes more efficiently e.g. the electricity grid, steel-making furnaces, chemical sythesising processes, nuclear power plants, fusion reactors;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c30ab",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some Motivating Statements\n",
    "\n",
    "2. Reinforcement learning (RL) provides a general enough framework for controlling any of these processes;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca476e65",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some Motivating Statements\n",
    "\n",
    "3. Conventional (online) RL agents require too much data and are too unreliable to be deployed in real systems;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78c283a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some Motivating Statements\n",
    "\n",
    "4. We can train RL agents *offline* using data collected from the system then deploy them. This kinda works, but they can only solve **one** task in the system e.g. maintain **one** temperature in a steel-making furnace. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90c7f04",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some Motivating Statements\n",
    "\n",
    "5. Previous work has proposed offline methods for solving **any** task in the system--zero-shot RL;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8bba15",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some Motivating Statements\n",
    "\n",
    "6. These methods assume access to unrealistically large datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e35b80",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Core Question\n",
    "\n",
    "**Can we develop new methods for doing zero-shot RL with realistic datasets?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc956e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Failings of the Existing Method "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d895a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Optimal Solutions\n",
    "\n",
    "<img class=\"\" src=\"https://github.com/enjeeneer/talks/blob/main/2023-10-10-RefficiencyLunch/images/vcfb-intuition-1.png?raw=true\" style=\"width:40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7065ec",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Forward-Backward Representations\n",
    "\n",
    "<img class=\"\" src=\"https://github.com/enjeeneer/talks/blob/main/2023-10-10-RefficiencyLunch/images/vcfb-intuition-2.png?raw=true\" style=\"width:40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e820b3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Forward-Backward Representation Overestimation\n",
    "\n",
    "<img class=\"\" src=\"https://github.com/enjeeneer/talks/blob/main/2023-10-10-RefficiencyLunch/images/overestimates.png?raw=true\" style=\"width:70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11e7faa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Our Fix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dbdf38",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## *Conservative* Forward-Backward Representations\n",
    "\n",
    "<img class=\"center\" src=\"https://github.com/enjeeneer/talks/blob/main/2023-10-10-RefficiencyLunch/images/vcfb-intuition-3.png?raw=true\" style=\"width:40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7151a9ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Didactic Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c194843c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img class=\"\" src=\"https://github.com/enjeeneer/talks/blob/main/2023-10-10-RefficiencyLunch/images/didactic-1.png?raw=true\" style=\"width:70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c071ec",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img class=\"\" src=\"https://github.com/enjeeneer/talks/blob/main/2023-10-10-RefficiencyLunch/images/didactic-4.png?raw=true\" style=\"width:70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2deb24",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img class=\"\" src=\"https://github.com/enjeeneer/talks/blob/main/2023-10-10-RefficiencyLunch/images/didactic-2.png?raw=true\" style=\"width:70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b429c1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img class=\"\" src=\"https://github.com/enjeeneer/talks/blob/main/2023-10-10-RefficiencyLunch/images/didactic-3.png?raw=true\" style=\"width:70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b650fd88",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291f2121",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Domains\n",
    "\n",
    "| **Domain** | **Dimensionality**   | **Type**         | **Reward**      | **Tasks** |\n",
    "| ---------- | ---------- | -------------- | -------------- | ------ |\n",
    "| Walker     | <span style=\"color:green\">Low</span>  | Locomotion  | <span style=\"color:green\">Dense</span>  | 4 |\n",
    "| Quadruped  | <span style=\"color:red\">High</span>  | Locomotion  | <span style=\"color:green\">Dense</span> | 5 |\n",
    "| Maze       | <span style=\"color:green\">Low</span>  | Goal-reaching   | <span style=\"color:red\">Sparse</span>  | 4| \n",
    "| Jaco       | <span style=\"color:red\">High</span>  | Goal-reaching     | <span style=\"color:red\">Sparse</span>     | 4| "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8930c93f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Datasets\n",
    "\n",
    "<img class=\"\" src=\"https://github.com/enjeeneer/talks/blob/main/2023-10-10-RefficiencyLunch/images/dataset-heatmap.png?raw=true\" style=\"width:70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae67555",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Aggregate Results\n",
    "\n",
    "<img class=\"\" src=\"https://github.com/enjeeneer/talks/blob/main/2023-10-10-RefficiencyLunch/images/performance-profiles-subplot.png?raw=true\" style=\"width:70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e169d0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Performance on Full Datasets\n",
    "\n",
    "| **Domain** | **Task**   | **FB**         | **VC-FB**      | **MC-FB**      |\n",
    "| ---------- | ---------- | -------------- | -------------- | -------------- |\n",
    "| Walker     | all tasks  | 639 (616–661)  | 659 (647–670)  | 651 (632–671)  |\n",
    "| Quadruped  | all tasks  | 656 (638–674)  | 579 (522–635)  | 635 (628–642)  |\n",
    "| Maze       | all tasks  | 219 (86–353)   | 287 (117–457)  | 261 (159–363)  |\n",
    "| Jaco       | all tasks  | 39 (29–50)     | 33 (24–42)     | 34 (18–51)     |\n",
    "| All        | all tasks  | 361            | **381**        | **381**        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548db24",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# (Minor) Limitations\n",
    "\n",
    "**Computational overhead.** Pre-training is 3x slower.\n",
    "\n",
    "**Learning instability.** Early-stopping required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f079a340",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thanks for listening!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
